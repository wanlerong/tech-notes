# kafka

基于发布与订阅的消息系统，一般会有一个broker，也就是发布消息的中心点。
Kafka 的数据是按照一定顺序持久化保存的，可以按需读取。


一个topic包含几个分区，因此无法在整个topic范围内保证消息的顺序，但可以保证消息在单个分区内的顺序。

### 消费者
消费者通过检查消息的偏移量来区分已经读取过的消息。偏移量是一个不断递增的整数值，在给定的分区里，每个消息的偏移量都是唯一的


![图](https://raw.githubusercontent.com/wanlerong/tech-notes/master/imgs/WX20240104-173724.png)



消费者群组有多个消费者，每个消费者负责topic下不同的分区。

![图](https://raw.githubusercontent.com/wanlerong/tech-notes/master/imgs/WX20240106-171655.png)


如果分区的数量，小于消费者的数量，那部分消费者就会闲置

消费者群组之间互不影响，每一个群组都会获得这个topic下的全部消息

添加或减少消费者，会导致分区的所有权从一个消费者转移到另一个消费者，这样的行为被称为再均衡。在再均衡期间，消费者无法读取消息，造成整个群组一小段时间的不可用。
消费者通过向被指派为群组协调器的 broker（不同的群组可以有不同的协调器）发送心跳来维持它们和群组的从属关系以及它们对分区的所有权关系。只要消费者以正常的时间间隔发送心跳，就被认为是活跃的，说明它还在读取分区里的消息。如果消费者停止发送心跳的时间足够长，会话就会过期，群组协调器认为它已经死亡，就会触发一次再均衡。
消费者会在轮询消息（为了获取消息）或提交偏移量时发送心跳。0.10.1 版本之后，也可以通过独立的线程发送心跳。

如果需要处理耗费较长时间的消息，只需要加大 max.poll.interval.ms 的值来增加轮询间隔的时长。避免被broker判断为死的消费者


当消费者要加入群组时，它会向群组协调器发送一个 JoinGroup 请求。第一个加入群组的消费者将成为“群主”。群主从协调器那里获得群组的成员列表（列表中包含了所有最近发送过心跳的消费者），并负责给每一个消费者分配分区。
分配完毕之后，群主把分配情况列表发送给群组协调器，协调器再把这些信息发送给所有消费者。


消费者也可以按照正则表达式去订阅主题

核心是轮询，在轮询中，会处理 群组协调、分区再均衡、发送心跳和获取数据。

一个消费者一个线程

更新分区当前位置的操作叫作提交(偏移量)。消费者往一个叫作 consumer_offset 的特殊主题发送消息，消息里包含每个分区
的偏移量。如果发生再均衡，消费者需要读取每个分区最后一次提交的偏移量，然后从偏移量指定的地方继续处理。


### 重复消费
如果提交的偏移量小于客户端处理的最后一个消息的偏移量，那么处于两个偏移量之间的消息就会被重复处理

![图](https://raw.githubusercontent.com/wanlerong/tech-notes/master/imgs/WX20240107-145534.png)

自动提交
最简单的提交方式是让消费者自动提交偏移量。如果 enable.auto.commit 被设为 true，那么每过 5s，消费者会自动把从 poll() 方法接收到的最大偏移量提交上去。提交时间间隔由 auto.commit.interval.ms 控制，默认值是 5s。与消费者里的其他东西一样，自动提交也是在轮询里进行的。
消费者每次在进行轮询时会检查是否该提交偏移量了，如果是，那么就会提交从上一次轮询返回的偏移量。

假设我们仍然使用默认的 5s 提交时间间隔，在最近一次提交之后的 3s 发生了再均衡，再均衡之后，消费者从最后一次提交的偏移量位置开始读取消息。这个时候偏移量已经落后了 3s，所以在这 3s 内到达的消息会被重复处理。

### 提交当前偏移量
关闭自动提交，让应用程序决定何时提交。使用 commitSync()提交偏移量最简单也最可靠。这个 API 会提交由 poll() 方法返回的最新偏移量，提交成功后马上返回，如果提交失败就抛出异常。只要没有发生不可恢复的错误，commitSync() 方法会一直尝试直至提交成功。如果提交失败，我们也只能把异常记录到错误日志里。
（但是发生再均衡后，还是会重复消费）

异步提交commitAsync()，缺点是它不会重试，因为避免网络问题，导致旧提交覆盖新的提交。可以维护一个自增的提交序列号，实现可重试的异步提交，类似乐观锁，序列号小于当前时，不重试。

同时使用同步和异步
一般情况下，针对偶尔出现的提交失败，不进行重试不会有太大问题，因为如果提交失败
是因为临时问题导致的，那么后续的提交总会有成功的。但如果这是发生在关闭消费者或
再均衡前的最后一次提交，就要确保能够提交成功。

![图](https://raw.githubusercontent.com/wanlerong/tech-notes/master/imgs/WX20240107-151320.png)


也可以提交特定的偏移量，比如在处理一批消息的中途提交offset，commitAsync() 中传 currentOffsets 参数
currentOffsets.put(new TopicPartition(record.topic(),
 record.partition()), new OffsetAndMetadata(record.offset()+1, "no metadata"));


在失去分区所有权之前通过 onPartitionsRevoked() 方法来提交偏移量。
用 ConsumerRebalanceListener 实例就可以了。ConsumerRebalanceListener 有
public void onPartitionsRevoked(Collection<TopicPartition> partitions) 方法会在
再均衡开始之前和消费者停止读取消息之后被调用。如果在这里提交偏移量，下一个接管分区的消费者就知道该从哪里开始读取了。

### 如果不想重复消费，也不想丢数据。

从特定偏移量处开始处理记录

如果保存记录和偏移量可以在一个原子操作里完成，就可以避免出现上述情况。记录和偏
移量要么都被成功提交，要么都不提交。如果记录是保存在数据库里而偏移量是提交到
Kafka 上，那么就无法实现原子操作。

所有可以把偏移量也保存在数据库里，而不是 Kafka 里。那么消费者在得到新分区
时怎么知道该从哪里开始读取？这个时候可以使用 seek() 方法。在消费者启动或分配到新
分区时，可以查找保存在数据库里的偏移量，使用 seek() 方法从特定偏移量处开始处理记录

ConsumerRebalanceListener 实例的
public void onPartitionsAssigned(Collection<TopicPartition>
 partitions) {
 for(TopicPartition partition: partitions)
 consumer.seek(partition, getOffsetFromDB(partition));
 }
}


## broker
一个独立的 Kafka 服务器被称为 broker。broker 接收来自生产者的消息，为消息设置偏移量，并提交消息到磁盘保存。broker 为消费者提供服务，对读取分区的请求作出响应，返回已经提交到磁盘上的消息。单个 broker 可以轻松处理数千个分区以及每秒百万级的消息量。

broker 是集群的组成部分。每个集群都有一个 broker 同时充当了集群控制器的角色（自动从集群的活跃成员中选举出来）。控制器负责管理工作，包括将分区分配给 broker 和监控broker。
在集群中，一个分区从属于一个 broker，该 broker 被称为分区的首领。一个分区可以分配给多个 broker，这个时候会发生分区复制。这种复制机制为分区提供了消息冗余，如果有一个 broker 失效，其他 broker 可以接管领导权。不过，相关的消费者和生产者都要重新连接到新的首领。

![图](https://raw.githubusercontent.com/wanlerong/tech-notes/master/imgs/WX20240104-174535.png)


保留消息（在一定期限内）是 Kafka 的一个重要特性。Kafka broker 默认的消息保留策略
是这样的：要么保留一段时间（比如 7 天），要么保留到消息达到一定大小的字节数（比
如 1GB）。
另外，紧凑型日志主题只为每个键保留最后一个变更数据，所以可以长时间使用，不需要担心消息过期问题。




## 多集群
随着 Kafka 部署数量的增加，基于以下几点原因，最好使用多个集群。
• 数据类型分离
• 安全需求隔离
• 多数据中心（灾难恢复）

Kafka 提供了一个叫作 MirrorMaker 的工具，可以用它来实现集群间的消息复制。


## 为什么选择Kafka

多个生产者
多个消费者,消费者之间互不影响。
基于磁盘的数据存储,允许非实时读取，消息可以持久化
灵活伸缩，broker数量可扩展，个别 broker失效，仍然可以持续地为客户提供服务
高性能，通过横向扩展生产者、消费者和 broker，Kafka 可以轻松处理巨大的消息流。在处理大量数据的同时，
它还能保证亚秒级的消息延迟。

![图](https://raw.githubusercontent.com/wanlerong/tech-notes/master/imgs/WX20240104-180052.png)


## 场景

- 埋点上报，跟踪用户的活动
- 消息传递
- 监控指标，日志记录
- 流处理
- 提交日志（binlog之类的数据库更新日志）


Zookeeper 用于保存 broker 元数据


## 如何选定 topic 的分区数量
如果每秒钟要从 topic 上写入和读取 1GB 的数据，并且每个消费者每秒钟可以处理 50MB
的数据，那么至少需要 20 个分区。这样就可以让 20 个消费者同时读取这些分区，从而达
到每秒钟 1GB 的吞吐量


## 需要多少个broker
首先，需要多少磁盘空间来保留数据，以及单个 broker 有多少空间可用。如果整个集群需要保留 10TB 的数据，每个
broker 可以存储 2TB，那么至少需要 5 个 broker。如果启用了数据复制，那么至少还需要
一倍的空间，不过这要取决于配置的复制系数是多少

网络带宽/磁盘吞吐量/内存不足：
如果单个 broker 的网络接口在高峰时段可以达到 80% 的使用量，并且有两个
消费者，那么消费者就无法保持峰值，除非有两个 broker。如果集群启用了复制功能，则
要把这个额外的消费者考虑在内。因磁盘吞吐量低和系统内存不足造成的性能问题，也可
以通过扩展多个 broker 来解决。


## 生产者

![图](https://raw.githubusercontent.com/wanlerong/tech-notes/master/imgs/WX20240104-234431.png)


序列化：序列化为字节数组，broker 希望接收到的消息的键和值都是字节数组。
已有的序列化器
- 字符串
- JSON、Avro、Thrift 或 Protobuf。


发送消息主要有以下 3 种方式。
发送并忘记（fire-and-forget）
我们把消息发送给服务器，但并不关心它是否正常到达。大多数情况下，消息会正常到
达，因为 Kafka 是高可用的，而且生产者会自动尝试重发。不过，使用这种方式有时候
也会丢失一些消息。
同步发送
我们使用 send() 方法发送消息，它会返回一个 Future 对象，调用 get() 方法进行等待，
就可以知道消息是否发送成功。
异步发送
我们调用 send() 方法，并指定一个回调函数，服务器在返回响应时调用该函数。


KafkaProducer 一般会发生两类错误。其中一类是可重试错误，这类错误可以通过重发消息
来解决。比如对于连接错误，可以通过再次建立连接来解决，“无主（no leader）”错误则可
以通过重新为分区选举首领来解决。KafkaProducer 可以被配置成自动重试，如果在多次重
试后仍无法解决问题，应用程序会收到一个重试异常。
另一类错误无法通过重试解决，比如“消息太大”异常。对于这类错误，KafkaProducer 不会进行任何重试，直接抛出异常。


保证消息的顺序。
Kafka 可以保证同一个分区里的消息是有序的。如果某些场景要求消息是有序的，那么消息是否写入成功也是
很关键的，所以不建议把 retries 设为 0。可以把 max.in.flight.requests.per.connection 设为 1，这样在生产者尝试发送第一批消息时，就不会有其他的消息发送给broker。不过这样会严重影响生产者的吞吐量，所以只有在
对消息的顺序有严格要求的情况下才能这么做。


保证消息不丢失
Default: all
acks 参数指定了必须要有多少个分区副本收到消息，生产者才会认为消息写入是成功的。
这个参数对消息丢失的可能性有重要影响。
如果 acks=0，生产者在成功写入消息之前不会等待任何来自服务器的响应。
如果 acks=1，只要集群的首领节点收到消息，生产者就会收到一个来自服务器的成功
响应。如果消息无法到达首领节点（比如首领节点崩溃，新的首领还没有被选举出来），
生产者会收到一个错误响应，为了避免数据丢失，生产者会重发消息。如果让发送客户端等待服务器的响应（通过调用 Future 对象的 get() 方法），显然会增加延迟（在网络上传输一个来回的延迟）。如果客户端使用回
调，延迟问题就可以得到缓解，不过吞吐量还是会受发送中消息数量的限制（比如，生
产者在收到服务器响应之前可以发送多少个消息）。
如果 acks=all，只有当所有参与复制的节点全部收到消息时，生产者才会收到一个来自
服务器的成功响应。这种模式是最安全的，它可以保证不止一个服务器收到消息，就算
有服务器发生崩溃，整个集群仍然可以运行。不过，它的延迟比 acks=1 时更高 (同步时)，因为我们要等待不只一个服务器节点接收消息。


如果有某个key的数据非常多，如特殊的供应商，可以自定义分区器，把某个/某些分区给这个key专用


